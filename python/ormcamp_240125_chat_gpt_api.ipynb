{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuy0ax6D865jZF/VZirmhC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/escape1001/ormcamp/blob/main/python/ormcamp_240125_chat_gpt_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0fbnCQsCx__",
        "outputId": "9502a0a5-9eb5-4423-91f3-f921222d4d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/223.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m215.0/223.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI  # OpenAI 모듈 불러오기\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "client = OpenAI(api_key='api-key')  # 사용자의 API 키로 대체해야 함\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\", # gpt4를 쓸것이냐 3.5를 쓸것이냐~\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Hello World!\"}] # 사용자가 하는 말\n",
        ")\n",
        "# API 응답에서 마지막 메시지의 내용을 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqlAgGy4C5Hn",
        "outputId": "9e7785d3-2133-421b-b09a-287e0fb52a1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [{\"role\" : \"user\", \"content\" : \"Translate the following korean text to English: 안녕하세요 오늘 날씨가 좋네요. 햇살이 맑아요\"}],\n",
        "        max_tokens=10,\n",
        "        temperature=0.7,\n",
        "        top_p=0.8,\n",
        "        frequency_penalty=0.2\n",
        "    )\n",
        "    print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4kyYNcvEbMG",
        "outputId": "cdd5a7a2-2085-497a-d5f5-b9b0c32241dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, today's weather is nice. The sunlight\n",
            "Hello, today's weather is nice. The sunlight\n",
            "Hello, today's weather is good. The sunlight\n",
            "Hello, the weather is nice today. The sunshine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_chatbot(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\", messages = messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "prompt_role = \"너는 블로그 전문가, 파워블로그처럼 글을 써야해. 개발자의 직업관에 대한 글을 써야하고, 그리고 취업을 준비하는 20대 독자들에게 잘 보일수 있도록 글을 써야해. SEO최적화된 글을 써야해\""
      ],
      "metadata": {
        "id": "F5wW3wwaQSUG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "def assist_blogger(\n",
        "    facts: List[str], tone: str, length_words: int, style: str\n",
        "):\n",
        "    facts = \", \".join(facts)\n",
        "    prompt_role = \"너는 블로그 전문가고, 파워블로그처럼 글을 써야해\"\n",
        "    prompt = f\"{prompt_role} \\\n",
        "            FACTS: {facts} \\\n",
        "            TONE: {tone} \\\n",
        "            LEGNTH: {length_words} words \\\n",
        "            STYLE: {style}\"\n",
        "    return ask_chatbot([{\"role\": \"user\", \"content\": prompt}])"
      ],
      "metadata": {
        "id": "8JOKUjAKQpmE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    assist_blogger(\n",
        "        [\"대학 진학 이후의 개발자의 삶은?\"], \"informal\", 100, \"blogpost\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "025oW6L0QxvC",
        "outputId": "aba4a439-ce1a-4422-ae9b-1baa9624f82a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 여러분이 찾아주신 삶의 진실을 전해드릴 블로거입니다. 오늘은 대학 진학 이후 개발자의 삶에 대해 이야기해보려고 합니다.\n",
            "\n",
            "개발자로 대학에 진학한 후에는 여러 방향으로 나아갈 수 있는 선택의 길이 열립니다. 일단 전통적인 길을 선택해 기업에 취업하는 것도 좋겠지만, 최근에는 차세대 기술에 힘을 실어주기 위해 스타트업을 창업하는 사람들도 많아지고 있어요.\n",
            "\n",
            "개발자의 삶은 꾸준한 자기계발이 필수라고 할 수 있습니다. 새로운 언어나 프로그래밍 기술을 익히기 위해 학습하는 시간을 항상 가져야 합니다. 또한, 팀원들과의 협업이나 프로젝트 관리 등 소프트 스킬도 키워야 합니다.\n",
            "\n",
            "물론, 개발자의 삶은 힘들기도 합니다. 어떤 시스템에 대한 오류를 해결하기 위해 한끼도 쉬지 못하고 야근을 하는 날도 있습니다. 하지만 그만큼의 성취도 함께 느낄 수 있죠.\n",
            "\n",
            "대학 진학 이후 개발자로서의 삶은 다양한 선택과 어려움이 함께하는 여정입니다. 하지만 현대 사회에선 IT 기술이 매우 중요한 위치를 차지하고 있어, 개발자로서 미래에 안정적인 직업을 선택하는 것도 꽤나 현명한 선택이 될 수 있습니다.\n",
            "\n",
            "그럼, 다음에도 진실을 전해드릴 블로거였습니다. 감사합니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    assist_blogger(\n",
        "        facts =[\"Chat GPT 등장이후의 취업 전략은?\"],\n",
        "        tone = \"정중하게\",\n",
        "        length_words = 200,\n",
        "        style= \"파워블로그 스럽게\"\n",
        "        )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJlpgYWQRF-p",
        "outputId": "a3d9b2cd-5191-403c-fbdf-c27194883e5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 여러분들은 Chat GPT가 등장한 이후의 취업 전략에 대해서 궁금한 적이 있으신가요? 오늘은 그에 대해 파워블로그 스타일로 알려드리고자 합니다.\n",
            "\n",
            "Chat GPT라는 인공지능 기술은 채팅 형식의 상호작용을 통해 사람과 기계 간의 자유로운 대화를 가능하게 해주는 혁신적인 기술입니다. 이번 글에서는 Chat GPT 등장 이후의 취업 전략에 대해 알아보고자 합니다.\n",
            "\n",
            "첫째, Chat GPT를 통한 실시간 면접 대응. Chat GPT는 대화 형식으로 질문과 답을 주고받는 형태를 취하기 때문에, 실시간 면접 대응에 활용할 수 있습니다. 이를 통해 면접자와의 자연스럽고 신속한 대화를 통해 좋은 인상을 남길 수 있습니다.\n",
            "\n",
            "둘째, Chat GPT를 활용한 이력서 작성. 이력서 작성은 취업에서 중요한 요소 중 하나입니다. Chat GPT를 활용하면 자신의 경험과 능력을 다른 사람에게 알리기 쉽게 작성할 수 있습니다. AI 기술의 도움을 받아 더욱 전문적이고 효과적인 이력서를 작성할 수 있습니다.\n",
            "\n",
            "셋째, Chat GPT 기반의 개별 취업 컨설팅. Chat GPT를 활용하면 취업 컨설팅을 인구 대신 AI가 하게 됩니다. AI는 사람들에게 맞춤형 조언을 제공하고 경력 개발에 도움을 줄 수 있습니다.\n",
            "\n",
            "위의 세 가지 방법은 Chat GPT의 등장 이후 취업 전략에 활용할 수 있는 몇 가지 사례입니다. Chat GPT의 기능을 완벽하게 활용하면 실시간 면접 대응, 이력서 작성, 개별 취업 컨설팅 등에서 큰 도움을 받을 수 있습니다. 새로운 시대의 도구인 Chat GPT를 배우고 활용하여 취업 시장에서의 경쟁력을 향상시키세요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트파일 가져와서 번역 + 요약하기"
      ],
      "metadata": {
        "id": "M6nZGFugUzAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첨부된 파일을 읽고 작은 부분으로 나누기 위한 코드입니다.\n",
        "\n",
        "# 파일 경로 설정\n",
        "file_path = '/content/English_But_what_is_a_neural_network____Chapter_1_Deep_learning_DownSub.com.txt'\n",
        "\n",
        "# 파일을 읽어서 내용을 저장\n",
        "with open(file_path, 'r') as file:\n",
        "    transcript = file.read()\n",
        "\n",
        "# 텍스트를 나눌 최대 길이 설정 (토큰 수가 아닌 문자 수 기준)\n",
        "max_length = 5000  # 각 부분의 최대 길이 (문자 수)\n",
        "\n",
        "# 텍스트를 작은 부분으로 나누는 함수\n",
        "def split_into_parts(text, length):\n",
        "    return [text[i:i+length] for i in range(0, len(text), length)]\n",
        "\n",
        "# 텍스트를 여러 부분으로 나눔\n",
        "parts = split_into_parts(transcript, max_length)\n",
        "\n",
        "# 나누어진 부분들의 수와 첫 부분의 내용 일부를 출력\n",
        "num_parts = len(parts)\n",
        "first_part_preview = parts[0][:500]  # 첫 부분의 처음 500자\n",
        "\n",
        "num_parts, first_part_preview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enj1v1NQTGvT",
        "outputId": "d7cc003b-3507-4a3a-c6ba-e47cec1af324"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " \"This is a 3. It's sloppily written and rendered at an extremely low resolution of 28x28 pixels,\\n\\nbut your brain has no trouble recognizing it as a 3. And I want you to take a moment\\n\\nto appreciate how crazy it is that brains can do this so effortlessly. I mean, this,\\n\\nthis and this are also recognizable as 3s, even though the specific values of each pixel\\n\\nis very different from one image to the next. The particular light-sensitive cells in your\\n\\neye that are firing when you see this 3 are very \")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 부분만 사용\n",
        "first_part = parts[0]\n",
        "\n",
        "# 첫 번째 부분에 대한 번역 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"너는 유튜브를 영어에서 한국어로 번역하는 번역가이자, 요약을 잘하는 역할을 할꺼야\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"업로드한 파일을 한국어로 변역해줘\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"한국어로 번역한 내용을 요약해\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : first_part}\n",
        "      ],\n",
        ")\n",
        "\n",
        "# 번역 결과 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xClC0C3hU4oK",
        "outputId": "6f4e0779-43bf-4d1a-ee6c-761a8484b347"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이것은 3입니다. 서툴게 쓰여 있고 28x28 픽셀의 매우 낮은 해상도로 렌더링되었지만, 당신의 뇌는 이것을 3으로 인식하는 데 어려움이 없습니다. 이것이 얼마나 믿을 수 없는 일인지 한 번 생각해보세요. 이것, 이것, 그리고 이것도 각자 다른 픽셀 값이지만 3으로 인식됩니다. 이 3을 볼 때 활성화되는 특정한 빛 감지 세포들은 이 3을 볼 때 활성화되는 다른 세포들과 매우 다릅니다. 그러나 당신의 똑똑하고 놀라운 시각 피질에서 어떤 것이든 같은 개념을 나타내며 동시에 다른 이미지를 자체적인 개념으로 인식합니다.\n",
            "\n",
            "하지만 만약 나에게 \"28x28 그리드를 받고 숫자 0과 10 사이의 하나의 숫자를 출력하는 프로그램을 작성해봐\"라고 말한다면, 일이 쉽게 해결 가능한 것에서 어렵게 바뀝니다. 돌로썬 산하에 살고 있다면, 기계 학습과 신경망이 현재와 미래에 대해 얼마나 필요하고 중요한지를 설득할 필요조차 없을 것이라고 생각합니다. 그러나 여기서는 배경 지식이 없는 사람들에게 신경망이 정확히 무엇인지를 보여주기를 바라며, 이를 수학적인 한 조각으로써 시각화하는 데에 도움을 주고자 합니다. 내 희망은 구조 자체가 동기부여 받았다는 느낌을 떠오르게 하고, 뉴럴 네트워크가 '학습'이라고 읽거나 들었을 때 그 의미를 알게 해주기를 바랍니다. 이 비디오는 구조의 구성 요소에만 주어져 있을 것이며, 다음 비디오에서는 학습에 대해 다룰 것입니다.\n",
            "\n",
            "우리가 할 일은 손으로 쓴 숫자를 인식할 수 있는 뉴럴 네트워크를 만드는 것입니다. 이것은 이 주제를 소개하는 데에는 다소 고전적인 예입니다. 이렇게 하는 것이 권장되는 이유는 이 두 비디오의 끝에서 더 배울 수 있는 좋은 자료와 코드를 다운로드하여 직접 컴퓨터에서 사용할 수 있는 자료로 안내할 예정이기 때문입니다. 뉴럴 네트워크에는 많은 변형이 있으며, 최근 몇 년간 이러한 변형에 대한 연구가 무척 늘어났지만, 이 두 가지 입문용 비디오에서는 우리가 추가적인 장식이 없는 가장 간단한 형태의 네트워크만을 살펴볼 것입니다. 이것은 더 강력한 현대적인 변형을 이해하기 위한 필요한 선행 조건이며, 그래도 우리가 이해할 수 있는 충분한 복잡성을 가지고 있습니다. 하지만 이 가장 간단한 형태에서도 손으로 쓴 숫자를 인식할 수 있으며, 컴퓨터가 할 수 있는 멋진 일입니다. 동시에 우리가 가질 수 있는 몇 가지 희망에서는 좀 더 부족한 점들이 보일 것입니다. 이름에서 알 수 있듯이, 뉴럴 네트워크는 뇌에서 영감을 받았습니다. 그렇다면 뉴런은 무엇이며, 어떤 의미에서 연결되어 있는 것일까요? 지금 내가 뉴런이라고 말할 때, 당신이 생각해야 할 것은 특정한 숫자를 가지고 있는 것, 구체적으로 0과 1 사이의 숫자를 가지고 있는 것입니다. 그 이상도 이하도 아닙니다. 예를 들어, 네트워크는 입력 이미지의 각 28x28 픽셀에 해당하는 뉴런의 모임으로 시작합니다. 이는 총 784개의 뉴런입니다. 각각은 해당 픽셀의 그레이스케일 값을 나타내는 숫자를 가지며, 검은 픽셀은 0부터 흰 픽셀은 1까지 범위 내의 값입니다. 이 뉴런 안에 있는 숫자는 그것의 활성화라고 불리며, 당신이 가따리는 이미지는 각각의 뉴런의 활성화 값이 높을 때 불이 켜진 것으로 생각하면 됩니다. 이 784개의 뉴런은 네트워크의 첫 번째 계층을 구성합니다. 마지막 계층으로 뛰어넘어가보죠. 이 계층은 10개의 뉴런을 가지며, 각각은 하나의 숫자를 나타냅니다. 이 뉴런 안에 있는 활성화는 다시 0과 1 사이의 숫자로, 시스템이 해당 이미지가 해당하는 숫자와 얼마나 일치하는지를 나타냅니다. 또한 더 중간에는 hidden layer라고 불리는 계층들이 있는데, 당장은 이 계층들이 숫자 인식 과정을 어떻게 처리할지에 대해 큰 의문이 될 것입니다. 이 네트워크에서는 두 개의 hidden layer를 선택했고, 각각에는 16개의 뉴런이 있습니다. 솔직히 말해서, 이는 어떻게 구조를 동기부여할 것인지를 조금 이후에 설명하고 싶었던 선택이고, 16은 화면에 잘 맞는 좋은 숫자였습니다. 실제로는이 구조에 대해 구체적인 실험이 많이 가능합니다. 각 계층에서의 활성화는 다음 계층의 활성화를 결정합니다. 당연히 네트워크의 정보 처리 메커니즘으로서 핵심은 한 계층에서의 활성화가 다음 계층에서의 활성화를 어떻게 가져오는가에 달려 있습니다. 이는 생물학적인 뉴런 네트워크에서 어떤 그룹의 뉴런들이 특정 다른 뉴런들을 활성화시킬 때와 조금 유사한 것으로 이루어져 있습니다. 여기서 보여주는 네트워크는 이미 숫자를 인식하기 위해 훈련되었습니다. 이제 당신에게 보여줄게요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 부분에 대한 번역 및 요약 결과를 저장할 리스트\n",
        "translated_summaries = []\n",
        "\n",
        "# 모든 부분에 대해 번역 및 요약 요청 수행\n",
        "for part in parts:\n",
        "    # 실제 환경에서는 이 부분에 API 요청을 넣어야 합니다.\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"너는 유튜브를 영어에서 한국어로 번역하는 번역가이자, 요약을 잘하는 역할을 할꺼야\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"업로드한 파일을 한국어로 변역해줘\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"한국어로 번역한 내용을 요약해\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : part}\n",
        "      ],\n",
        "    )\n",
        "    # 번역 및 요약 결과 저장\n",
        "    translated_summary = response.choices[0].message.content\n",
        "    translated_summaries.append(translated_summary)\n",
        "\n",
        "# 모든 결과를 하나의 문자열로 결합\n",
        "final_result = '\\n\\n'.join(translated_summaries)\n",
        "\n",
        "# 최종 결과 출력\n",
        "print(final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWFTmrR0U7I9",
        "outputId": "8ad64a8f-f0e1-4311-d3da-7b638c7b9f94"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이것은 3입니다. 손으로 조잡하게 쓰였고, 28x28 픽셀의 매우 낮은 해상도로 렌더링되었습니다. 하지만 당신의 뇌는 이것을 3으로 인식하는 데 전혀 문제가 없습니다. 정말 놀라운 것은 뇌가 이를 매우 쉽게 처리할 수 있다는 것입니다. 이 3, 이 3, 그리고 이 3도 모두 3으로 인식됩니다. 각 픽셀의 구체적인 값은 이미지에서 이미지로 매우 다르지만, 당신의 눈에 있는 특정한 빛 감지 세포는 이 3을 볼 때와 다른 3을 볼 때 활성화됩니다. 하지만 당신의 미친 스마트 시각 피질 어딘가에서는 이들이 같은 개념을 나타내고 있는지 동시에 다른 이미지를 각각 고유한 개념으로 인식합니다. 하지만 나에게, \"자, 28x28 그리드를 입력받아 0과 10 사이의 하나의 숫자를 출력하는 프로그램을 작성해봐. 숫자가 무엇인지 말해봐\"라고 말한다면, 이 일은 조롱스럽게 너무 간단한 것에서 겁나게 어려운 것으로 변합니다. 돌 아래에서 살고 있다면, 기계 학습과 신경망의 관련성과 중요성을 설득할 필요가 없을 것이라고 생각합니다. 그러나 여기서 내가 하고 싶은 것은 신경망이라는 것이 실제로 무엇인지, 배경 지식이 없다고 가정하고 이해하기 쉽게 시각화하는 것입니다. 나는 그 구조 자체가 동기를 얻었다고 느끼기를 희망하고, 신경망이 '학습'이라고 읽거나 들을 때 그것이 의미하는 바를 알고 있다고 느끼기를 희망합니다. 이 비디오는 그 구조 부분에만 전념하며, 그 다음 비디오는 학습을 다룰 것입니다. 우리가 할 것은 손으로 쓴 숫자를 인식할 수 있는 신경망을 만드는 것입니다. 이것은 이 주제를 소개하는 데 어느 정도 고전적인 예제입니다. 나는 여기서 상태를 그대로 유지하기를 원하기 때문에 이것을 따라가기로 결정했습니다. 왜냐하면 이 두 개의 비디오를 마친 후에는 더 많은 내용을 배울 수 있는 좋은 자원과 코드를 다운로드하여 직접 컴퓨터에서 사용할 수 있는 장소로 안내하려고 하기 때문입니다. 신경망에는 많은 변종이 있으며, 최근 몇 년간 이러한 변종에 대한 연구가 급증하고 있습니다. 그러나 두 개의 입문 비디오에서는 추가 기능이 없는 가장 간단한 '플레인 바닐라(Vanilla)' 형태만 살펴볼 것입니다. 이것은 더 강력한 현대적인 변종 중 어느 것을 이해하기 위한 필수적인 선결 조건입니다. 그리고 실제로 우리의 머릿속에서 포장해야 할 복잡성도 충분합니다. 하지만 이 가장 단순한 형태조차도 손으로 쓴 숫자를 인식하는 것을 학습할 수 있습니다. 컴퓨터가 할 수 있는 멋진 일입니다. 동시에 실제로는 우리가 가지고 있는 몇 가지 희망에는 아직 부족하다는 것을 알 수 있을 것입니다. 위에서 언급한 대로, 신경망은 뇌에서 영감을 받았지만 자세히 살펴보겠습니다. 신경세포(neuron)는 어떤 의미에서 서로 연결되어 있는 건가요? 지금 내가 'neuron(뉴런)'이라고 말할 때, 당신이 생각하는 것은 0과 1 사이의 숫자를 가지고 있는 것입니다. 더 많은 것을 의미하지 않습니다. 예를 들어, 네트워크는 입력 이미지의 28x28 픽셀 각각에 해당하는 뉴런들로 시작합니다. 전체적으로는 784개의 뉴런이 있습니다. 각각은 해당 픽셀의 회색조 값(0부터 검은색, 1까지 흰색)을 나타내는 숫자를 가집니다. 이 뉴런 내의 숫자를 '활성화(activation)'라고 부르며, 뉴런이 높은 수치일 때 비춰진다는 이미지를 가지고 있습니다. 이 784개의 뉴런은 네트워크의 첫 번째 계층을 이루고 있습니다. 이제 마지막 계층으로 넘어가면, 10개의 뉴런이 있습니다. 각각은 숫자 하나를 나타냅니다. 이 뉴런 내의 활성화 역시 0과 1 사이의 숫자로, 시스템이 주어진 이미지가 주어진 숫자와 얼마나 일치하는지를 나타냅니다. 가운데에는 'hidden layer(은닉 계층)'라는 몇 개의 계층이 있는데, 우리는 현재 이 계층이 어떻게 숫자 인식을 다룰지에 대해서는 아직 큰 의문을 가지고 있어야 합니다. 이 네트워크에서는 은닉 계층으로 두 개를 선택했고, 각각 16개의 뉴런이 있습니다. 솔직히 말해서, 이것은 좀 무작위로 선택한 것입니다. 솔직히 말해서, 나는 구조를 설득하기 위해 방금 애초부터 두 계층을 선택했고, 16은 화면에 맞게 좋은 숫자였습니다. 현재의 구조에서도 특정 구조에서 실험을 할 여지가 많이 있습니다. 네트워크의 작동 방식은 한 계층의 활성화가 다음 계층의 활성화를 결정합니다. 물론 정보 처리 메커니즘으로서의 신경망의 핵심은 어떻게 계층 간의 활성화가 다른 계층의 활성화를 가져오는지에 따라 지어집니다. 이것은 생물학적인 신경 세포의 네트워크에서 어떤 뉴런 그룹이 선을 그리며 다른 그룹의 발화를 일으키는 것과 느슨하게 유사하다고 볼 수 있습니다. 지금 제시된 네트워크는 이미 숫자를 인식하기 위해 훈련되었습니다. 그리고 보여 드릴 것입니다.\n",
            "\n",
            "이것은 이미지를 인식하는 인공신경망의 구조와 동작 원리에 대한 이야기입니다. 인공신경망은 입력층의 모든 뉴런을 이미지의 각 픽셀의 밝기에 따라 활성화시킵니다. 그리고 이러한 활성화 패턴은 다음층에 매우 특정한 패턴을 유발하고, 그 다음 층에서는 어떤 패턴을 유발하고, 마지막으로 출력층에서는 어떤 숫자를 나타내는지를 결정합니다. 이때 출력층의 가장 밝은 뉴런은 네트워크가 해당 이미지가 어떤 숫자를 나타내는지 선택한 것입니다. 이러한 계층 구조가 지능적으로 작동할 수 있는 이유에 대해 이야기하며, 가장 바깥쪽 층에서 가장 안쪽 층까지의 연속적인 구성 요소를 인식하고 이를 숫자로 연결하는 학습이 이루어진다는 것을 설명합니다. 이러한 구성 요소를 인식하거나 올바른 구성 요소를 학습하는 방법에 대해서도 다루고 있습니다. 이러한 계층 구조는 이미지 인식 뿐만 아니라 다른 인식 작업에도 유용하며, 음성 인식과 같은 작업에서도 유사한 원리를 적용할 수 있다고 설명합니다. 이번에는 한 층의 뉴런 활성화가 다음 층의 활성화에 어떻게 영향을 주는지에 대해 설명하고 있으며, 가중치를 통해 연결된 뉴런 간의 상호작용을 조절한다고 설명합니다. 또한 특정한 예시를 통해 가중치 조정을 통해 특정한 패턴 인식이 가능하도록 설계하는 방법에 대해 이야기합니다. 마지막으로, 각 픽셀의 가중치 합을 계산하여 해당 지역의 가중치에 따라 값을 추가하는 방식으로 특정 패턴을 인식할 수 있음을 설명합니다.\n",
            "\n",
            "우리는 신경망의 두 번째 층의 뉴런이 어떤 픽셀 패턴을 감지하는지를 가리키는 가중치(Weights)와 어떤 가중합(Sum)이 가치 있는 활동을 시작하기 위해 얼마나 커야하는지를 가리키는 편향(Bias)로 구성됩니다. 이것은 한 뉴런에 대한 설명이고, 매우 복잡합니다. 이 히든 레이어(16개의 뉴런)로 구성된 네트워크에는 총 13,000개 이상의 가중치와 편향이 있습니다. 이 많은 수의 매개 변수를 조작하여 네트워크가 원하는 방식으로 작동하도록 학습시키는 것이 학습이라고 합니다. 이 가중치와 편향을 수동으로 조작하여 네트워크가 엣지를 인식하고 패턴을 인식하는 등의 작업을 수행할 수 있습니다. 이 가중치와 편향의 의미에 대한 이해를 갖고 있다면, 네트워크가 예상대로 작동하지 않을 때 어떻게 구조를 변경하여 개선하는지 실험해 볼 수 있습니다. 또한, 네트워크가 예상 에펙트를 발휘하지만 예상한 이유와 다를 때, 가중치와 편향이 어떻게 작용하는지 파악하는 것은 가설을 도전하고 가능한 솔루션의 모든 영역을 노출시키는 좋은 방법입니다. 실제로는 이러한 연결을 표현하는 것이 조금 번거로운 것 같습니다. 그래서 이러한 연결을 더 압축적인 방식으로 표현하는 방법을 보여드릴게요. 이것은 신경망에 대해 더 자세히 알고 싶은 경우에 참고할 수 있는 방법입니다. 한 층의 모든 활성화를 열(column)로 구성하여 벡터로 나타냅니다. 다음 층의 특정 뉴런과의 연결을 나타내는 행마다 가중치를 포함하는 행렬로 모든 가중치를 구성합니다. 이는 첫 번째 층의 활성화의 가중합을 이 가중치에 따라 구하는 것이 됩니다. 이 표현 대신, 각 값에 편향을 독립적으로 추가하는 대신, 모든 편향을 벡터로 구성하여 이전의 행렬 - 벡터 곱에 전체 벡터를 추가로 더합니다. 그런 다음 최종 단계로 외부에 시그모이드를 래핑하여 결과 벡터의 각 구성 요소에 시그모이드 함수를 적용합니다. 이렇게 가중치 행렬과 벡터를 기호로 나타내면...\n",
            "\n",
            "다음 층으로의 활성화 전이를 굉장히 간결하고 깔끔하게 표현할 수 있으며, 이로 인해 관련 코드는 훨씬 간단하고 빠르게 작동합니다. 왜냐하면 많은 라이브러리들이 행렬 곱셈을 최적화하기 때문입니다. 이 뉴런들이 단순히 숫자를 가지고 있는 것이라고 이야기했던 것 기억하시나요? 그렇습니다. 당연히 그들이 가지고 있는 특정 숫자는 입력된 이미지에 따라 달라집니다. 그래서 사실상 각 뉴런을 함수로 생각하는 것이 더 정확합니다. 이 함수는 이전 층의 모든 뉴런의 출력을 입력으로 받아 0에서 1 사이의 숫자를 출력합니다. 실제로 전체 네트워크는 이러한 함수로 이루어져 있습니다. 784개의 숫자를 입력으로 받아 10개의 숫자를 출력으로 내놓는 함수입니다. 이것은 엄청나게 복잡한 함수입니다. 이 함수는 이러한 가중치와 바이어스의 형태로 13,000개의 파라미터를 포함하며, 특정한 패턴을 파악하는데 사용됩니다. 또한 많은 행렬 벡터 곱셈과 시그모이드 함수를 반복하는 작업이 필요합니다. 그래도 결국 이것은 그저 함수에 불과합니다. 그리고 어떤 면에서 복잡해 보인다는 것은 좀 안정감을 주는 것 같습니다. 말하자면, 만약 이 함수가 더 단순하다면, 숫자를 인식하는 도전을 할 수 있을까요? 그리고 이 네트워크는 어떻게 도전을 수행할까요? 이 네트워크는 데이터를 보고 적절한 가중치와 바이어스를 어떻게 학습하는 걸까요? 이건 저번 영상에서 얘기하고, 이 네트워크가 실제로 무슨 일을 하는지 좀 더 파헤쳐볼 것입니다. 다음 비디오와 새로운 비디오가 출시되면 알림을 받기 위해 구독해주세요라고 말해야 할 때입니다. 하지만 사실상 대부분의 사람들은 유튜브에서 알림을 받지 않으시죠? 솔직하게 말하면 이 채널의 콘텐츠를 권장하기 원한다는 신호를 유튜브의 추천 알고리즘에 전달하기 위해 구독해야겠다고 말하는 것일지도 모릅니다. 어쨌든 더 많은 내용을 기대해주세요. 이 비디오를 패트리온에서 지원해주시는 모든 분들께 정말 감사드립니다. 이번 여름에는 확률 시리즈를 속도를 좀 늦추었는데, 이 프로젝트 다음에 다시 시작하려고 합니다. 그래서 후원자분들은 그곳에서 업데이트를 확인하실 수 있습니다. 여기에서 당신과 함께 해주신 이샤 리가 있습니다. 그녀는 딥러닝의 이론적인 측면에 대한 박사 학위를 취득한 바 있으며, 현재 Amplify Partners라는 벤처 투자 회사에서 일하고 있습니다. 이 비디오에 일부 자금을 제공해 주셨습니다. 이샤, 빠르게 언급해야 할 점 하나가 시그모이드 함수입니다. 제가 이해하기로, 초기 네트워크에서는 가중치 합을 0과 1 사이의 구간으로 압축하는 데 이 함수를 사용했는데, 이는 신경세포의 생물학적 유사성에서 영감을 받은 것 같습니다. 맞습니다. 하지만 최근 네트워크에서는 시그모이드를 거의 사용하지 않습니다. 네, 그게 옛날 방식이라고 할 수 있겠네요. 네, 혹은 조금 더 정확히 말하면 ReLU가 학습하기 훨씬 쉬운 것 같습니다. ReLU는 렉티파이드 리니어 유닛의 약자입니다, 맞습니까? 네 맞습니다. 이 함수는 0과 a의 최댓값을 취하는 함수로, a는 비디오에서 설명한 것과 같이 정해진 것인데, 이는 신경세포가 활성화되거나 활성화되지 않은 상태를 나타내는 생물학적 유사성에서 영감을 얻었습니다. 그래서 특정한 임계값을 넘으면 항등 함수가 되지만, 그렇지 않으면 활성화되지 않으므로 0이 됩니다. 그래서 간소화된 표현입니다. 시그모이드를 사용하지 않고 ReLU를 사용하는 것은 학습에 도움이 되지 않았거나 어려움을 겪은 것이었을까요? 한때 학습이 매우 어려웠는데, 사람들이 ReLU를 시도해보고 매우 잘 작동했습니다. 이렇게 엄청나게 깊은 신경망에 대해 말하고 있습니다. 그래서 감사합니다, 이샤. \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqzguukNVJm1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}